#!/usr/bin/env python

from __future__ import print_function

from copy import deepcopy
import docopt
import jinja2
import os
from os import path
from sys import stdin, stderr
import pkg_resources
import yaml
from pprint import pprint
from subprocess import call

CLI_DOC = """
USAGE:
    chunksub.py [-q QUEUE -n NCPUS -w TIME -m MEM -d WDIR\
    -c CONFIG -t TEMPLATE -s CHUNKSIZE -j JOB_DIR] \
    -N NAME [<command>] [<arguments>]

OPTIONS:
    -q --queue      QUEUE     Queue name (normal/express/copyq)
    -n --ncpus      NCPUS     Processors per node
    -w --wtime      WTIME     Walltime to request
    -N --name       NAME      Job name (will be basename of chunks & jobs)
    -m --mem        MEM       RAM to request
    -d --wdir       WDIR      Job's working directory [default: ./]

    -c --config     CONFIG    Path to yaml config file [default: ~/.chunksub/config]
    -t --template   TEMPLATE  Jinja2 template for job file (default: integrated template)
    -s --chunksize  CHUNKSIZE Number of lines per chunk [default: 16]
    -j --job_dir    JOB_DIR   Directory to save the job files. [default ./chunksub]
    -X --execute    EXECUTE   Execute qsub instead of printing the command to STDOUT [default: yes]
"""

CONFIG_FIELDS = {
    'queue': str,
    'ncpus': int,
    'wtime': str,
    'name': str,
    'mem': str,
    'wdir': str,
    'template': str,
    'chunk_size': int,
    'job_dir': str,
    'execute': lambda x: True if x.lower() in ['y', 'yes', 'true'] else False
}

CLI_CONFIG_MAPPING = {
    '-q': 'queue',
    '-n': 'ncpus',
    '-w': 'wtime',
    '-N': 'name',
    '-m': 'mem',
    '-d': 'wdir',
    '-t': 'template',
    '-l': 'chunk_size',
    '-j': "job_dir",
    '-X': "execute"
}


def get_job_template(fname):
    """Create job template with jinja2"""
    with open(fname) as tfh:
        template = tfh.read()
    return jinja2.Template(template)


def load_config(fname):
    """Load config from yaml"""
    fname = path.expanduser(fname)
    try:
        with open(fname) as cfh:
            config = yaml.load(cfh)
    except IOError:
        print("ERROR: non-existant config file", fname, file=stderr)
        exit(1)
    return config


def make_config(opts):
    """Parses the CLI and loads the config dict"""
    # load config file if specified
    if opts['-c']:
        config_file = opts['-c']
    if path.exists(config_file):
        config = load_config(config_file)
    else:
        config = {}

    # command line options override those from the yaml config
    for cli, cfg in CLI_CONFIG_MAPPING.items():
        if opts[cli]:
            config[cfg] = opts[cli]

    # the command to execute with qsub
    config['command'] = opts['<command>']
    # append placeholder for xargs if not already in command.
    if '{}' not in config['command']:
        config['command'] += " {}"

    # file containing the argument list
    if opts['<arguments>'] is None:
        config['arg_file'] = stdin
    else:
        config['arg_file'] = open(opts['<arguments>'])

    # sanitize config fields
    for field, sanitiser in CONFIG_FIELDS.items():
        if field not in config:
            config[field] = None
        else:
            config[field] = sanitiser(config[field])

    # force absolute paths
    if config['wdir'].startswith('.'):
        config['wdir'] = path.abspath(config['wdir'])

    # load default template if not specified
    if config['template'] is None:
        config['template'] = pkg_resources.resource_string(__name__, "job_template")

    return config


def get_file_name(dir, n, ext=None):
    """
    Retrieve full filename for an index number.

    >>> wd = "/tmp/user"
    >>> get_file_name(wd, 5, ext=".job")
    '/tmp/user/0005.job'
    """
    namer = path.join(dir, "{:04d}")
    if ext is not None:
        namer += ext
    return namer.format(n)


def make_chunks(chunksub_dir, arg_fileh, chunk_size):
    """
    Read an argument file and split it into chunks.

    Args:
        chunksub_dir: chunksub working directory. Create the chunk files there.
        arg_fileh: Filehandle of the input file. Will be split into chunks.
        chunk_size: number of lines per output file.

    Yields:
        File name of a chunk file.

    """
    chunk_idx = 0
    chunk_fh = None
    for idx, record in enumerate(arg_fileh):
        if idx % chunk_size == 0:
            if chunk_fh is not None:
                chunk_fh.close()
            chunk_file = get_file_name(chunksub_dir, chunk_idx, ".chunk")
            chunk_fh = open(chunk_file, 'w')
            chunk_idx += 1
            yield chunk_file
        chunk_fh.write(record)


def run_job_files(job_files, execute=True):
    for job_file in job_files:
        if execute:
            call(["qsub", job_file])
        else:
            print("qsub {}".format(job_file))


def main():
    """
    Read an argument file, split it into chunks and create a job file
    for each chunk.
    """
    opts = docopt.docopt(CLI_DOC)
    config = make_config(opts)
    pprint("CONFIGURATION:", stream=stderr)
    pprint(config, stream=stderr)
    template = get_job_template(config['template'])

    # make chunksub working directory (create .job and .chunk files there)
    chunksub_dir = path.join(config['wdir'], config['job_dir'], config['name'])
    if not path.isdir(chunksub_dir):
        os.makedirs(chunksub_dir)

    # split argument file into chunks and create job files.
    job_files = []
    for job_id, chunk_file in enumerate(make_chunks(
            chunksub_dir, config['arg_file'], config['chunk_size'])):
        this_config = deepcopy(config)
        this_config['chunk_file'] = chunk_file
        this_config['stdout'] = get_file_name(chunksub_dir, job_id, ".out")
        this_config['stderr'] = get_file_name(chunksub_dir, job_id, ".err")
        job_file = get_file_name(chunksub_dir, job_id, ".job")
        with open(job_file, 'w') as jfh:
            jfh.write(template.render(**this_config) + '\n')
        job_files.append(job_file)

    # run jobs
    run_job_files(job_files, config['execute'])

    config['arg_file'].close()

if __name__ == '__main__':
    main()
